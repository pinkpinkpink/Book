jdbc:hive2://***/default;hive.server2.proxy.user=p113_u157_18919025924

https://www.ileapcloud.com/ileapcloud.html#/product/leapHD
18919025924
zaq12wsx


- kettle

作业job

转换transformation

- 跳

- 单向通道

创建资源库

作业和转换的关系

timestamp 实现数据库增量同步操作

execl、文本文件导入数据库

# 数据分析

查询

hive

jdbc

json

# 数据集成

添加数据源

RDB

大数据组件 to hive Hbase HDFS

AWS S3 亚马逊云

mysql导入到hive


datahub execl

HDFS导入Hive

数据分析

# 数据服务

HTTP、Get、json

脚本模式创建 sql

注册模式创建API

API申请和授权

用户

# 系统管理

# 离线批处理

导入导出

hive mapreduce

spark

mysql oracle pg oracle

mapreduce

kettle 

shell

java

存储过程

http

HDFS 文件大小数量

流程定义

mysql 查询语句

分支判断

# 实时流处理

kafka存储

服务地址 三个主机地址

scheme JSON

# 数据目录

元数据：描述数据的数据

˝

海量数据存储与计算
 支持结构化、非结构化海量数据存储，支持 HDFS、Hive 、HBase；
 支持基于 MapReduce 的批处理和 HBase API 处理数据；
 支持通过脚本、Java 程序、API、SQL 等多种方式进行数据查询分析；
 支持 Hadoop 数据的多源、多类型的导入与导出；
 提供可视化的 SQL 执行 IDE，支持 Hive、Spark、Impala 的数据查询及结果输出；
 支持 HDFS 文件管理；
 支持存储过程执行；


通过集成汇聚某电信企业用户的业务消费数据，分析该企业的客户人群特征，以及不同客户群体的消费特点，便于洞察电信用户消费习惯，帮助企业优化产品研发和营销策略。


案例主要内容
导入数据。使用数据集成将Excel内电信用户信息及消费记录数据导入大数据平台。
数据清洗转换。进行Excel数据解析、字符转换等处理。
数据加载及任务配置。将数据加载至Hive，并启动数据同步任务。
创建数据加工流程。实现数据加工及任务调度。
数据关联及聚合。通过数据关联及数据聚合进行数据开发。
数据质量监控（可选）。监控用户业务明细表的质量情况。
数据查询分析。通过SQL简单查询分析加工的数据。
生成数据服务API。将加工好的数据表生成API，供业务系统消费调用。
数据可视化报表（可选）。通过BI工具构建数据仪表盘。
准备工作
ileapcloud用户注册
申请LeapHD联想大数据平台试用


汽车企业生产数据分析
汽车企业面临日益激烈的市场竞争，生产订单按时完成率将直接影响汽车企业的市场份额和赢利水平。本场景通过获取企业来自ERP的生产计划数据和MES系统的生产入库数据，分析汽车企业的生产订单完成率，便于企业优化生产，提高产能的目标。


案例主要内容
数据导入。使用数据集成工具导入生产计划表和生产入库表到大数据平台；
数据清洗转换。对生产入库表增加时间戳、字符剔除、字符替换处理；
数据同步。配置数据同步任务；
数据查找。在大数据平台的数据目录中，查找汽车基础数据表信息；
数据关联。通过数据开发，将生产入库表、生产计划表与汽车基础信息表进行表关联，生成汽车生产订单明细表；
数据聚合。在开发流程中，在汽车生产订单明细表中计算“生产订单完成率”；
数据查询。通过SQL简单查询“生产订单完成率”；
生成数据服务API。将“生产订单完成率”生成API服务。
